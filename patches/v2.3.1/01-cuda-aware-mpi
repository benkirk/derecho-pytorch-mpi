diff --git a/caffe2/mpi/mpi_ops_gpu.cc b/caffe2/mpi/mpi_ops_gpu.cc
index bb645a5c78..d3c085c225 100644
--- a/caffe2/mpi/mpi_ops_gpu.cc
+++ b/caffe2/mpi/mpi_ops_gpu.cc
@@ -35,10 +35,10 @@ namespace caffe2 {
 #endif // CAFFE2_OMPI_VERSION >= 10805
 #endif // CAFFE2_OMPI_VERSION >= 2000
 #else // !OPEN_MPI
-// We have not really tested against other MPI environments, so let's go for a
-// safe path and basically say we don't have cuda-aware functions.
-#define CAFFE2_HAS_CUDA_MPI_BASICS 0
-#define CAFFE2_HAS_CUDA_MPI_ALLREDUCE 0
+// We have not really tested against other MPI environments,
+// hard-code we have cuda-aware functions.
+#define CAFFE2_HAS_CUDA_MPI_BASICS 1
+#define CAFFE2_HAS_CUDA_MPI_ALLREDUCE 1
 #endif // OPEN_MPI
 
 // We allow a macro to force using fallback functions.
diff --git a/torch/csrc/distributed/c10d/ProcessGroupMPI.cpp b/torch/csrc/distributed/c10d/ProcessGroupMPI.cpp
index 939f120268..c50d4a8a2c 100644
--- a/torch/csrc/distributed/c10d/ProcessGroupMPI.cpp
+++ b/torch/csrc/distributed/c10d/ProcessGroupMPI.cpp
@@ -46,8 +46,7 @@ std::map<at::ScalarType, MPI_Datatype> mpiDatatype = {
     {at::kShort, MPI_SHORT},
 };
 
-// Checking CUDA-aware MPI support, currently we only support CUDA aware
-// MPI ops through Open MPI
+// Checking CUDA-aware MPI support
 bool cudaAwareMpiCheck() {
 // Run time check
 #if defined(MPIX_CUDA_AWARE_SUPPORT)
@@ -57,7 +56,11 @@ bool cudaAwareMpiCheck() {
     return false;
   }
 #else // !defined(MPIX_CUDA_AWARE_SUPPORT)
-  return false;
+  {
+    //BSK: these tests assume OpenMPI, bypass-to-true with cray-mpich on Derecho
+    //return false;
+    return true;
+  }
 #endif // MPIX_CUDA_AWARE_SUPPORT
 }
 
